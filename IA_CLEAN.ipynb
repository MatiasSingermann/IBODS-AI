{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uMWHqmwEoonk",
        "we25ghDBoz4k",
        "Rf_R0LmKo7tH",
        "1LJza3uUpoOo"
      ],
      "authorship_tag": "ABX9TyOd1pfU/wHj5jNaFHLKo2sF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasSingermann/IBODS-AI/blob/main/IA_CLEAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacion e instalacion de librerias"
      ],
      "metadata": {
        "id": "YD2VImwGmGJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B9jQTvYlmCAn",
        "outputId": "20d072a7-d109-4d9b-b00f-7c1a9b928e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.17.tar.gz (25 kB)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 38.2 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.23.0)\n",
            "Collecting requests_toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 61.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: roboflow, wget\n",
            "  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for roboflow: filename=roboflow-0.2.17-py3-none-any.whl size=31935 sha256=20325d6f6b37e1cf6bb0e61fdc09c2ed0e7c0f20c44591a0f998cf35f924e1c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/38/3c/b4ac4d8a9d9b44bdcd51f6148ec810b0f05a404e5fed8df48d\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=8893bde797854c75b888ef32e65fcf0c033f2e673e38503a51c4cca946ad0c56\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built roboflow wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.17 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8COx3UfJmOeO",
        "outputId": "36e6b8c6-2b6c-4d07-9186-bd5e3d6004cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.2-py3-none-any.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 17.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (6.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (4.6.0)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (2.9.2)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.9 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[K     |████████████████████████████████| 840 kB 39.2 MB/s \n",
            "\u001b[?25hCollecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 17.6 MB/s \n",
            "\u001b[?25hCollecting tflite-support>=0.4.2\n",
            "  Downloading tflite_support-0.4.2-cp37-cp37m-manylinux2014_x86_64.whl (60.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.2 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.12.0)\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (4.9.1)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 19.0 MB/s \n",
            "\u001b[?25hCollecting scann==1.2.6\n",
            "  Downloading scann-1.2.6-cp37-cp37m-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting tensorflowjs<3.19.0,>=2.4.0\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.21.6)\n",
            "Requirement already satisfied: matplotlib<3.5.0,>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (3.2.2)\n",
            "Collecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.29.32)\n",
            "Requirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.3.0)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (7.1.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (3.0.0)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53->tflite-model-maker) (57.4.0)\n",
            "Collecting tensorflow>=2.6.0\n",
            "  Downloading tensorflow-2.8.3-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.9 MB 28 kB/s \n",
            "\u001b[?25hCollecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (5.4.8)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.5.12)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.3.5)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.21.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (4.6.0.66)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.12.11)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.1->tflite-model-maker) (2.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.17.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.28.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.56.4)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2022.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.9)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (6.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (4.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from neural-structured-learning>=1.3.1->tflite-model-maker) (22.1.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (2.21)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.50.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.6.3)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.27.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.1.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.6.0->tflite-model-maker) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.9.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.11.2->tflite-model-maker) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.10.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (5.10.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.8.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.10.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.5->tflite-model-maker) (0.1.7)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.4 MB/s \n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (1.3)\n",
            "Building wheels for collected packages: fire, py-cpuinfo\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=e8427531dda8f26966b5b7da3ee9f3cb835a5c55f13ee9db676b9b4ea0220d03\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=286a16c62cf4bcc488fdff8f42a8d6516edbca7dbc280d52b5dbc7b3a057b448\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "Successfully built fire py-cpuinfo\n",
            "Installing collected packages: urllib3, protobuf, packaging, llvmlite, tensorflow-estimator, tensorboard, numba, keras, flatbuffers, tf-slim, tensorflow-model-optimization, tensorflow-addons, tensorflow, sounddevice, sentencepiece, pybind11, py-cpuinfo, dataclasses, tflite-support, tf-models-official, tensorflowjs, scann, neural-structured-learning, fire, tflite-model-maker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.6\n",
            "    Uninstalling urllib3-1.26.6:\n",
            "      Successfully uninstalled urllib3-1.26.6\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.3\n",
            "    Uninstalling numba-0.56.3:\n",
            "      Successfully uninstalled numba-0.56.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "roboflow 0.2.17 requires urllib3==1.26.6, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 fire-0.4.0 flatbuffers-22.9.24 keras-2.8.0 llvmlite-0.36.0 neural-structured-learning-1.4.0 numba-0.53.0 packaging-20.9 protobuf-3.19.6 py-cpuinfo-8.0.0 pybind11-2.10.0 scann-1.2.6 sentencepiece-0.1.97 sounddevice-0.4.5 tensorboard-2.8.0 tensorflow-2.8.3 tensorflow-addons-0.18.0 tensorflow-estimator-2.8.0 tensorflow-model-optimization-0.7.3 tensorflowjs-3.18.0 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.2 tflite-support-0.4.2 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `Tensorflow` y varios de sus **modulos**."
      ],
      "metadata": {
        "id": "SqB_uiCqmRhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tflite_model_maker import object_detector\n",
        "import tensorflow_hub as hub\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_support.task import vision\n",
        "from tflite_support.task.vision import ObjectDetector\n",
        "from tflite_support.task.vision import ObjectDetectorOptions\n",
        "from tflite_support.task.processor import DetectionOptions\n",
        "from tflite_support.task.core import BaseOptions"
      ],
      "metadata": {
        "id": "tXV1oBSmmR5n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo varias `librerias` que me permiten trabajar con **tensores**, y **operaciones matematicas** necesrias. "
      ],
      "metadata": {
        "id": "79MykpSfmaXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "KZOSDS6tma-E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `librerias` para **administrar archivos** y seleccionar de manera **random** alguno de ellos"
      ],
      "metadata": {
        "id": "J_rKhmWmmg8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "Gc5A4SDhmkMH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `librerias` que me permiten trabajar con las **imagenes** del dataset."
      ],
      "metadata": {
        "id": "cq8dFtRPmn9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from itertools import product\n",
        "from skimage import draw, transform"
      ],
      "metadata": {
        "id": "cIJu9w4UmoDX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `Roboflow` para acceder al dataset"
      ],
      "metadata": {
        "id": "e_yTfBIrmtq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "g2HBu838mznI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacion del **Dataset** y sus **labels**"
      ],
      "metadata": {
        "id": "YbD44He-m8MI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Me conecto a mi cuenta de Drive para agarrar ciertos archivos"
      ],
      "metadata": {
        "id": "BL2X8Gp9nWZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvjknquxnUjH",
        "outputId": "87d24937-2dd0-41c4-e764-2c5685255f3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo el dataset desde Roboflow"
      ],
      "metadata": {
        "id": "G-X3KZaSna4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"41l2d60Eq7cWhUOVgPxd\")\n",
        "project = rf.workspace(\"ibods\").project(\"ibods_lbl\")\n",
        "dataset = project.version(1).download(\"voc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2tfSwUanD40",
        "outputId": "6424e2b6-72a4-4082-9310-fe97412e4cc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in IBODS_LBL-1 to voc: 100% [157029367 / 157029367] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to IBODS_LBL-1 in voc:: 100%|██████████| 7031/7031 [00:03<00:00, 2025.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asigno la **ruta del archivo** de las anotaciones a una variable"
      ],
      "metadata": {
        "id": "zij8UDnCnjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_lbl = '/content/gdrive/MyDrive/Proyecto 4to/I.A/Anotaciones/labels.txt'"
      ],
      "metadata": {
        "id": "72ozUQ5inoSs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abro el **archivo de anotaciones** y lo *recorro linea por linea*, *eliminando los espacios* y metiendo los `strings` en una `lista`"
      ],
      "metadata": {
        "id": "JJE5EpcdnrZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_lbl) as f:\n",
        "   labels = [line.strip() for line in f.readlines()]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIUF-rPRn0Bm",
        "outputId": "3981f529-a9b8-4a9a-da3b-5f673923e433"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cordon',\n",
              " 'autos',\n",
              " 'personas',\n",
              " 'cruces',\n",
              " 'pozos',\n",
              " 'parar',\n",
              " 'cruzar',\n",
              " 'bicicleta',\n",
              " 'moto',\n",
              " 'escalones']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando el **arhcivo de labels**, le asigno un *valor numerico* para que la `IA` pueda interpretar las anotaciones"
      ],
      "metadata": {
        "id": "YbYsoSkhn1-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assigned_labels = { i : labels[i] for i in range(0, len(labels) ) }\n",
        "assigned_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPXmSf4Un4Kd",
        "outputId": "7e84354d-3bd2-462b-a507-17c0716acedb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'cordon',\n",
              " 1: 'autos',\n",
              " 2: 'personas',\n",
              " 3: 'cruces',\n",
              " 4: 'pozos',\n",
              " 5: 'parar',\n",
              " 6: 'cruzar',\n",
              " 7: 'bicicleta',\n",
              " 8: 'moto',\n",
              " 9: 'escalones'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones Utiles y configuracion"
      ],
      "metadata": {
        "id": "CDDgePjQoCCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = labels"
      ],
      "metadata": {
        "id": "Z3DtEabhoCjD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = np.random.randint(0, 255, size=(len(CLASSES), 3), dtype=np.uint8)"
      ],
      "metadata": {
        "id": "Gsj3FE2ioGqt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, input_size):\n",
        "  ''' Preprocess the input image to feed to the TFLite model\n",
        "  '''\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
        "  return resized_img, original_image"
      ],
      "metadata": {
        "id": "rXD6vgJSoZpC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(interpreter, image, threshold):\n",
        "  ''' Returns a list of detection results, each a dictionary of object info.\n",
        "  '''\n",
        "\n",
        "  signature_fn = interpreter.get_signature_runner()\n",
        "\n",
        "  # Feed the input image to the model\n",
        "  output = signature_fn(images=image)\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  count = int(np.squeeze(output['output_0']))\n",
        "  scores = np.squeeze(output['output_1'])\n",
        "  classes = np.squeeze(output['output_2'])\n",
        "  boxes = np.squeeze(output['output_3'])\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results"
      ],
      "metadata": {
        "id": "Ghxh4WZ-oaLH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  ''' Run object detection on the input image and draw the detection results\n",
        "  '''\n",
        "  \n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(CLASSES[class_id], obj['score'] * 100)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8"
      ],
      "metadata": {
        "id": "m68Xs6DYocVO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_box (image, model_path, threshold):\n",
        "  base_opt = BaseOptions(model_path)\n",
        "\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  tensor_image = vision.TensorImage.create_from_file(image)\n",
        "\n",
        "  results = detector.detect(tensor_image)\n",
        "\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "    categories = obj.categories\n",
        "    for category in categories:\n",
        "      names = category.category_name\n",
        "      scores = category.score * 100\n",
        "    percentages = [float(scores)]\n",
        "    for percentage in percentages:\n",
        "      confidence = str(int(percentage)) + '%'\n",
        "      label = names + \", \" + confidence\n",
        "\n",
        "  return label"
      ],
      "metadata": {
        "id": "Ber_JMXAEhM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar Dataset"
      ],
      "metadata": {
        "id": "3N3z-QDrooH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de entrenamiento"
      ],
      "metadata": {
        "id": "uMWHqmwEoonk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = 'IBODS_LBL-1/train'"
      ],
      "metadata": {
        "id": "InmLpA7UouAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    TRAIN_PATH,\n",
        "    TRAIN_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "V-Z4DiDIowbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de validacion"
      ],
      "metadata": {
        "id": "we25ghDBoz4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALID_PATH = 'IBODS_LBL-1/valid'"
      ],
      "metadata": {
        "id": "dKrF-Fbdo0cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    VALID_PATH,\n",
        "    VALID_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "EVpeegbdo2sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de testeo"
      ],
      "metadata": {
        "id": "Rf_R0LmKo7tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_PATH = 'IBODS_LBL-1/test'"
      ],
      "metadata": {
        "id": "wub7vz2Mo95l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    TEST_PATH,\n",
        "    TEST_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "rmNJlBOoo-l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de la IA"
      ],
      "metadata": {
        "id": "kfmDFT7WpObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = object_detector.create(\n",
        "    train_data,\n",
        "    model_spec= 'efficientdet_lite1',\n",
        "    batch_size= 8,\n",
        "    train_whole_model=True,\n",
        "    epochs=100,\n",
        "    validation_data=valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "4LV1ms_3pO-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testeo de la IA y su performance"
      ],
      "metadata": {
        "id": "dnZ4nw2HpRHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Hmk8-aIgpTjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvo el modelo"
      ],
      "metadata": {
        "id": "xLiSt_KKpY96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('logs')"
      ],
      "metadata": {
        "id": "oULQdRCKpd8-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(export_dir='logs')"
      ],
      "metadata": {
        "id": "vYi2BYIipiab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_tflite('logs/model.tflite', test_data)"
      ],
      "metadata": {
        "id": "sZLF_VFDploi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "1LJza3uUpoOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = QuantizationConfig.for_float16()"
      ],
      "metadata": {
        "id": "VsgwnBNSpo1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('logs/model1.tflite')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "7SHpEPMepsXy",
        "outputId": "112fb287-adcf-4a22-e786-fed81e3049a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-fac64049725a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/model1.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtflite_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 949\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   debug_info_path = file_io.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     raise IOError(\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         f\"{constants.SAVED_MODEL_FILENAME_PB}}}\")\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: logs/model1.tflite/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deteccion"
      ],
      "metadata": {
        "id": "ZgUNYM4Pps7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion **simple** fotos"
      ],
      "metadata": {
        "id": "3gEnhMAMpy4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_opt = BaseOptions(\n",
        "    'logs/model1.tflite'\n",
        ")"
      ],
      "metadata": {
        "id": "UO7KUyNULaD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_opt = DetectionOptions(\n",
        "    score_threshold = 0.3, \n",
        ")"
      ],
      "metadata": {
        "id": "4dobkkEYJcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = ObjectDetectorOptions(\n",
        "    base_opt,\n",
        "    detection_opt\n",
        ")"
      ],
      "metadata": {
        "id": "VByFhTjfL40y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = ObjectDetector.create_from_options(\n",
        "    options\n",
        ")"
      ],
      "metadata": {
        "id": "14KXpdC2AQX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = vision.ObjectDetector.create_from_file('logs/model1.tflite')"
      ],
      "metadata": {
        "id": "mrOyAoyYqOHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_image = vision.TensorImage.create_from_file('IBODS_LBL-1/test/60_jpg.rf.af5b4d9b99351329bad5223344640506.jpg')"
      ],
      "metadata": {
        "id": "gR4vBgxdqQOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector.detect(tensor_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nurUDYkPbtl",
        "outputId": "8f26d46e-70f5-4bd4-9430-8d3addd41f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetectionResult(detections=[Detection(bounding_box=BoundingBox(origin_x=63, origin_y=44, width=102, height=76), categories=[Category(index=1, score=0.9296875, display_name='', category_name='autos')]), Detection(bounding_box=BoundingBox(origin_x=43, origin_y=179, width=371, height=196), categories=[Category(index=4, score=0.85546875, display_name='', category_name='pozos')]), Detection(bounding_box=BoundingBox(origin_x=158, origin_y=61, width=67, height=55), categories=[Category(index=1, score=0.765625, display_name='', category_name='autos')]), Detection(bounding_box=BoundingBox(origin_x=240, origin_y=78, width=43, height=36), categories=[Category(index=1, score=0.6875, display_name='', category_name='autos')])])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = detector.detect(tensor_image)"
      ],
      "metadata": {
        "id": "neMJCmkCqSTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsdetect = results.detections"
      ],
      "metadata": {
        "id": "tXwWqlSzR0VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsdetect[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raswBIj7xPN-",
        "outputId": "d1c46041-4750-4652-e997-0ec880bf5d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Detection(bounding_box=BoundingBox(origin_x=63, origin_y=44, width=102, height=76), categories=[Category(index=1, score=0.9296875, display_name='', category_name='autos')])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  box = obj.bounding_box\n",
        "  print(box)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3Qlpk9DPeX4",
        "outputId": "ec3f2edb-914f-47eb-b36c-7445a7adb63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoundingBox(origin_x=63, origin_y=44, width=102, height=76)\n",
            "BoundingBox(origin_x=43, origin_y=179, width=371, height=196)\n",
            "BoundingBox(origin_x=158, origin_y=61, width=67, height=55)\n",
            "BoundingBox(origin_x=240, origin_y=78, width=43, height=36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    scores = category.score * 100\n",
        "  percentages = [float(scores)]\n",
        "  for percentage in percentages:\n",
        "    confidence = str(int(percentage)) + '%'\n",
        "    label = names + \", \" + confidence\n",
        "    print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXmM4gz-bbM",
        "outputId": "43d42af1-6ff9-4aed-d7f0-ec815e6e8a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autos, 92%\n",
            "pozos, 85%\n",
            "autos, 76%\n",
            "autos, 68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    print(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zaq7eR4tBlzP",
        "outputId": "99192b2a-a197-4915-deed-c4f308a163d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autos\n",
            "pozos\n",
            "autos\n",
            "autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "\n",
        "image_path = '145.jpg'\n",
        "model_path = 'logs/model1.tflite'\n",
        "threshold = 0.3\n",
        "\n",
        "tensor_image = vision.TensorImage.create_from_file(image_path)\n",
        "image = Image.open(image_path)\n",
        "image = np.asarray(image)\n",
        "wid = image.shape[1]\n",
        "left = wid/3\n",
        "center = left * 2\n",
        "right = wid \n",
        "\n",
        "base_opt = BaseOptions(model_path)\n",
        "detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "results = detector.detect(tensor_image)\n",
        "\n",
        "resultsdetect = results.detections\n",
        "\n",
        "_TEXT_COLOR = (0, 0, 255)\n",
        "\n",
        "for obj in resultsdetect:\n",
        "  print(obj.bounding_box.width, obj.bounding_box.height)\n",
        "  start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "  end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "  detect_img = cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "  x1 = obj.bounding_box.origin_x\n",
        "  x2 = obj.bounding_box.origin_x + obj.bounding_box.width\n",
        "  middle = obj.bounding_box.width / 2\n",
        "  Center = x2 - middle\n",
        "  x = (x1, x2)\n",
        "  if Center < left:\n",
        "    position = \"izquierda\"\n",
        "  elif Center < center:\n",
        "    position = \"centro\"\n",
        "  else:\n",
        "    position = \"derecha\"\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    scores = category.score * 100\n",
        "  percentages = [float(scores)]\n",
        "  for percentage in percentages:\n",
        "    confidence = str(int(percentage)) + '%'\n",
        "    label = names + \", \" + confidence + \", \" + position\n",
        "  cv2.putText(image, label, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "  \n",
        "img = Image.fromarray(detect_img, 'RGB')\n",
        "img.save(f'{cwd}/result/output.png')\n",
        "img.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvnsr0I3lnxQ",
        "outputId": "4a650576-e561-4219-a678-8922cefdd851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "212 408\n",
            "421\n",
            "40 118\n",
            "145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drawBoundingBox(image_path, model_path, threshold, classes):\n",
        "\n",
        "  # Agarro el directorio (carpeta) actual\n",
        "  cwd = os.getcwd()\n",
        "\n",
        "  # Le asigno los tres parametros:\n",
        "  # - La ruta de la imagen a detectar\n",
        "  # - La ruta del modelo de IA\n",
        "  # - El umbral de la IA\n",
        "\n",
        "  image_path = image_path\n",
        "  model_path = model_path\n",
        "  threshold = threshold\n",
        "\n",
        "  # Leo la imagen como un tensor\n",
        "  tensor_image = vision.TensorImage.create_from_file(image_path)\n",
        "\n",
        "  # Abro y leo la imagen como un array\n",
        "  image = Image.open(image_path)\n",
        "  image = np.asarray(image)\n",
        "\n",
        "  # Divido la imagen en 3 (Izquierda, derecha y centro) utilizando el ancho de la imagen\n",
        "\n",
        "  wid = image.shape[1]\n",
        "  left = wid/3\n",
        "  center = left * 2\n",
        "  right = wid \n",
        "\n",
        "  # Asigno las opciones de configuracion del modelo de deteccion (Que modelo, el umbral, etc)\n",
        "  base_opt = BaseOptions(model_path)\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  # Creo el modelo de deteccion\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  # Agarro los resultados de la deteccion\n",
        "  results = detector.detect(tensor_image)\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  # Creo un randomizador de colores por clase\n",
        "  CLASSES = classes\n",
        "  COLORS = np.random.randint(0, 255, size=(len(CLASSES), 3), dtype=np.uint8)\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "    categories = obj.categories\n",
        "    for category in categories:\n",
        "      names = category.category_name\n",
        "      scores = category.score * 100\n",
        "      class_id = category.index\n",
        "    percentages = [float(scores)]\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "    end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "    detect_img = cv2.rectangle(image, start_point, end_point, color, 2)\n",
        "    x1 = obj.bounding_box.origin_x\n",
        "    x2 = obj.bounding_box.origin_x + obj.bounding_box.width\n",
        "    middle = obj.bounding_box.width / 2\n",
        "    Center = x2 - middle\n",
        "    x = (x1, x2)\n",
        "    if Center < left:\n",
        "      position = \"izquierda\"\n",
        "    elif Center < center:\n",
        "      position = \"centro\"\n",
        "    else:\n",
        "      position = \"derecha\"\n",
        "    for percentage in percentages:\n",
        "      confidence = str(int(percentage)) + '%'\n",
        "      label = names + \", \" + confidence\n",
        "      cv2.putText(image, label, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "      cv2.putText(image, position, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "      \n",
        "  img = Image.fromarray(detect_img, 'RGB')\n",
        "  return img"
      ],
      "metadata": {
        "id": "18qRcDLRAoR_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = drawBoundingBox('IBODS_LBL-1/test/60_jpg.rf.af5b4d9b99351329bad5223344640506.jpg','logs/model1.tflite', 0.3, labels)\n",
        "img.save(f'{cwd}/result/output.png')"
      ],
      "metadata": {
        "id": "tf6y1Rcm-xLF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "os.mkdir(f'{cwd}/result')"
      ],
      "metadata": {
        "id": "vMfbx6j9LzTM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion **compleja** fotos"
      ],
      "metadata": {
        "id": "hE4m-KPaqWRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "os.mkdir(f'{cwd}/result')"
      ],
      "metadata": {
        "id": "qRkGBtB0qWzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "\n",
        "DETECTION_THRESHOLD = 0.3\n",
        "\n",
        "# Change the test file path to your test image\n",
        "INPUT_IMAGE_PATH = 'IBODS_LBL-1/test/00--91-_png_jpg.rf.d3502e507f2bb074188f809e480b2fdb.jpg'\n",
        "\n",
        "im = Image.open(INPUT_IMAGE_PATH)\n",
        "im.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "im.save(f'{cwd}/result/input.png','PNG')\n",
        "\n",
        "# Load the TFLite model\n",
        "model_path = 'logs/model1.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Run inference and draw detection result on the local copy of the original file\n",
        "detection_result_image = run_odt_and_draw_results(\n",
        "    INPUT_IMAGE_PATH,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "# Show the detection result\n",
        "img = Image.fromarray(detection_result_image)\n",
        "img.save(f'{cwd}/result/output.png')"
      ],
      "metadata": {
        "id": "hJ_pluR7qbXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion en video"
      ],
      "metadata": {
        "id": "XIEa4jO8qftk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = vision.ObjectDetector.create_from_file('logs/model1.tflite')\n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"No se puede abrir la camara\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "  ret,frame = cap.read() # Voy agarrando los frames\n",
        "\n",
        "  if ret == True: # Si leyo correctamente los frames, signfica que el retun (ret) es true, por lo que ejecuto el codigo en ese caso\n",
        "    cv2.cvtColor(frame, cv2.COLOR_BGRRGB) # Convierto todos los frames al espectro RGB\n",
        "    tensor_image = vision.TensorImage.create_from_array(frame) # Convierto todos los frames a tensores\n",
        "    detector.detect(tensor_image)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "  if not ret:\n",
        "        print(\"No puedo recibir imagenes (finalizaste la trasmision?). Saliendo ...\")\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "JDsFyKYHqgPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codigo Viejo o Extra"
      ],
      "metadata": {
        "id": "q3zb9BL8eIg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drawBox(image_path, model_path, threshold):\n",
        "\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  base_opt = BaseOptions(model_path)\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  results = detector.detect(image)\n",
        "\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  _TEXT_COLOR = (0, 0, 255)\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "    start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "    end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "  detect_img = cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "   \n",
        "  return detect_img"
      ],
      "metadata": {
        "id": "Y2rqYo4WMVYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}