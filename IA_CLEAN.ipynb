{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uMWHqmwEoonk",
        "we25ghDBoz4k",
        "Rf_R0LmKo7tH",
        "1LJza3uUpoOo"
      ],
      "authorship_tag": "ABX9TyPFcLglMbVnMkvbQdgPRrNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasSingermann/IBODS-AI/blob/main/IA_CLEAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacion e instalacion de librerias"
      ],
      "metadata": {
        "id": "YD2VImwGmGJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B9jQTvYlmCAn",
        "outputId": "9d1ebe1c-e384-42a9-e3f1-b2fee317bda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.18-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 166 kB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 23.4 MB/s \n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 83.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=5bad85ceda234d2794a59cc13133e7e4b4b8dc2b8c284627c4507970c674440f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.18 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8COx3UfJmOeO",
        "outputId": "412b62b3-4056-487f-9119-18731112e795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.2-py3-none-any.whl (577 kB)\n",
            "\u001b[K     |████████████████████████████████| 577 kB 14.2 MB/s \n",
            "\u001b[?25hCollecting tflite-support>=0.4.2\n",
            "  Downloading tflite_support-0.4.2-cp37-cp37m-manylinux2014_x86_64.whl (60.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.8.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (6.0)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (7.1.2)\n",
            "Collecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.12.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.5.0,>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.29.32)\n",
            "Requirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (2.9.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.15.0)\n",
            "Collecting scann==1.2.6\n",
            "  Downloading scann-1.2.6-cp37-cp37m-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[K     |████████████████████████████████| 840 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.6.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (4.9.1)\n",
            "Collecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (4.6.0)\n",
            "Collecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.3.0)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.7.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.11.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.2.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.0.2)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 119.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53->tflite-model-maker) (57.4.0)\n",
            "Collecting tensorflow>=2.6.0\n",
            "  Downloading tensorflow-2.8.3-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.9 MB 37 kB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.5.12)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.12.11)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (5.4.8)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.21.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (4.6.0.66)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.3.5)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.1->tflite-model-maker) (2.0.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.17.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.31.6)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.56.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2022.5)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.28.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (0.4.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2021.5.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (4.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from neural-structured-learning>=1.3.1->tflite-model-maker) (22.1.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (2.21)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (14.0.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.14.1)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 61.0 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.27.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.6.0->tflite-model-maker) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.11.2->tflite-model-maker) (2.7.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.10.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (5.10.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.3.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.5->tflite-model-maker) (0.1.7)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 82.3 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 91.0 MB/s \n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (1.3)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=16804b2edf2ca2914c6bcabaae2554ec9b85ed779b64e0554d569c2a3a1352c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: urllib3, protobuf, packaging, llvmlite, tensorflow-estimator, tensorboard, numba, keras, flatbuffers, tf-slim, tensorflow-model-optimization, tensorflow-addons, tensorflow, sounddevice, sentencepiece, pybind11, py-cpuinfo, dataclasses, tflite-support, tf-models-official, tensorflowjs, scann, neural-structured-learning, fire, tflite-model-maker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.6\n",
            "    Uninstalling urllib3-1.26.6:\n",
            "      Successfully uninstalled urllib3-1.26.6\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.3\n",
            "    Uninstalling numba-0.56.3:\n",
            "      Successfully uninstalled numba-0.56.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "roboflow 0.2.18 requires urllib3==1.26.6, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 fire-0.4.0 flatbuffers-22.10.26 keras-2.8.0 llvmlite-0.36.0 neural-structured-learning-1.4.0 numba-0.53.0 packaging-20.9 protobuf-3.19.6 py-cpuinfo-9.0.0 pybind11-2.10.1 scann-1.2.6 sentencepiece-0.1.97 sounddevice-0.4.5 tensorboard-2.8.0 tensorflow-2.8.3 tensorflow-addons-0.18.0 tensorflow-estimator-2.8.0 tensorflow-model-optimization-0.7.3 tensorflowjs-3.18.0 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.2 tflite-support-0.4.2 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `Tensorflow` y varios de sus **modulos**."
      ],
      "metadata": {
        "id": "SqB_uiCqmRhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tflite_model_maker import object_detector\n",
        "import tensorflow_hub as hub\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_support.task import vision\n",
        "from tflite_support.task.vision import ObjectDetector\n",
        "from tflite_support.task.vision import ObjectDetectorOptions\n",
        "from tflite_support.task.processor import DetectionOptions\n",
        "from tflite_support.task.core import BaseOptions"
      ],
      "metadata": {
        "id": "tXV1oBSmmR5n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2w2mlGB6Zwf",
        "outputId": "73194fa9-e323-43b3-802d-1b659ad70f57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.3.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "aiohttp                       3.8.3\n",
            "aiosignal                     1.2.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "asynctest                     0.13.0\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.1.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "Babel                         2.10.3\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.1\n",
            "blis                          0.7.9\n",
            "bokeh                         2.3.3\n",
            "branca                        0.5.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     2.0.8\n",
            "certifi                       2021.5.30\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.2\n",
            "chardet                       4.0.0\n",
            "charset-normalizer            2.1.1\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   1.5.0\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.0.8\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.3\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.1\n",
            "cycler                        0.10.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.32\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.0\n",
            "dataclasses                   0.6\n",
            "datascience                   0.17.5\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.6\n",
            "distributed                   2022.2.0\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.7\n",
            "dnspython                     2.2.1\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.329\n",
            "easydict                      1.10\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.1\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         0.8.0\n",
            "etuples                       0.3.8\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.9\n",
            "fastcore                      1.5.27\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.16.2\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8\n",
            "feather-format                0.4.1\n",
            "filelock                      3.8.0\n",
            "fire                          0.4.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   22.10.26\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.1\n",
            "fsspec                        2022.10.0\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.6\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.2\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.4\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.3.post0\n",
            "grpcio                        1.50.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.16\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "importlib-metadata            4.13.0\n",
            "importlib-resources           5.10.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2022.2.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.23\n",
            "jaxlib                        0.3.22+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.2.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter-core                  4.11.2\n",
            "jupyterlab-widgets            3.0.3\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.8.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      14.0.6\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.36.0\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.9.1\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.18.0\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.0.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.2\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.7.0\n",
            "netCDF4                       1.6.1\n",
            "networkx                      2.6.3\n",
            "neural-structured-learning    1.4.0\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.5.0\n",
            "numba                         0.53.0\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.6.0.66\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     20.9\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.2\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.6.2\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.4.1\n",
            "progressbar2                  3.38.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.1\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    9.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pybind11                      2.10.1\n",
            "pycocotools                   2.0.5\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydantic                      1.10.2\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pylev                         1.4.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       4.3.2\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.1\n",
            "pysimdjson                    3.2.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-dotenv                 0.21.0\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.2\n",
            "python-utils                  3.3.3\n",
            "pytz                          2022.5\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        6.0\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post2\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.28.1\n",
            "requests-oauthlib             1.3.1\n",
            "requests-toolbelt             0.10.1\n",
            "resampy                       0.4.2\n",
            "roboflow                      0.2.18\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "scann                         1.2.6\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.5.post1\n",
            "six                           1.15.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "sounddevice                   0.4.5\n",
            "soundfile                     0.11.0\n",
            "spacy                         3.4.2\n",
            "spacy-legacy                  3.0.10\n",
            "spacy-loggers                 1.0.3\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.42\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.5\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.1.0\n",
            "tensorboard                   2.8.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.8.3\n",
            "tensorflow-addons             0.18.0\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.8.0\n",
            "tensorflow-gcs-config         2.9.1\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.27.0\n",
            "tensorflow-metadata           1.10.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflowjs                  3.18.0\n",
            "termcolor                     2.0.1\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.3.0\n",
            "tf-slim                       1.1.0\n",
            "tflite-model-maker            0.4.2\n",
            "tflite-support                0.4.2\n",
            "thinc                         8.1.5\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.12.1+cu113\n",
            "torchaudio                    0.12.1+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.13.1\n",
            "torchvision                   0.13.1+cu113\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.4.2\n",
            "typing-extensions             4.1.1\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.25.11\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.5\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wget                          3.2\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.6.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        0.20.2\n",
            "xarray-einstats               0.2.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.1\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxYn3JaS9YW5",
        "outputId": "a321e55d-5f82-4064-d44c-6181233c7614"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo varias `librerias` que me permiten trabajar con **tensores**, y **operaciones matematicas** necesrias. "
      ],
      "metadata": {
        "id": "79MykpSfmaXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import operator as op\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "KZOSDS6tma-E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `librerias` para **administrar archivos** y seleccionar de manera **random** alguno de ellos"
      ],
      "metadata": {
        "id": "J_rKhmWmmg8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "Gc5A4SDhmkMH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `librerias` que me permiten trabajar con las **imagenes** del dataset."
      ],
      "metadata": {
        "id": "cq8dFtRPmn9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from itertools import product\n",
        "from skimage import draw, transform"
      ],
      "metadata": {
        "id": "cIJu9w4UmoDX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo `Roboflow` para acceder al dataset"
      ],
      "metadata": {
        "id": "e_yTfBIrmtq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "g2HBu838mznI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacion del **Dataset** y sus **labels**"
      ],
      "metadata": {
        "id": "YbD44He-m8MI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Me conecto a mi cuenta de Drive para agarrar ciertos archivos"
      ],
      "metadata": {
        "id": "BL2X8Gp9nWZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvjknquxnUjH",
        "outputId": "26c34a54-139e-42a1-c8bb-e63e8b45e278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo el dataset desde Roboflow"
      ],
      "metadata": {
        "id": "G-X3KZaSna4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"41l2d60Eq7cWhUOVgPxd\")\n",
        "project = rf.workspace(\"ibods\").project(\"ibods_lbl\")\n",
        "dataset = project.version(1).download(\"voc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2tfSwUanD40",
        "outputId": "5fffa516-25d2-4340-fe8a-d60a8735d9eb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in IBODS_LBL-1 to voc: 100% [157029367 / 157029367] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to IBODS_LBL-1 in voc:: 100%|██████████| 7031/7031 [00:02<00:00, 2841.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asigno la **ruta del archivo** de las anotaciones a una variable"
      ],
      "metadata": {
        "id": "zij8UDnCnjso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_lbl = '/content/gdrive/MyDrive/Proyecto 4to/I.A/Anotaciones/labels.txt'"
      ],
      "metadata": {
        "id": "72ozUQ5inoSs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abro el **archivo de anotaciones** y lo *recorro linea por linea*, *eliminando los espacios* y metiendo los `strings` en una `lista`"
      ],
      "metadata": {
        "id": "JJE5EpcdnrZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_lbl) as f:\n",
        "   labels = [line.strip() for line in f.readlines()]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIUF-rPRn0Bm",
        "outputId": "d4d339c5-3896-4661-e41d-91e2d15385ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cordon',\n",
              " 'autos',\n",
              " 'personas',\n",
              " 'cruces',\n",
              " 'pozos',\n",
              " 'parar',\n",
              " 'cruzar',\n",
              " 'bicicleta',\n",
              " 'moto',\n",
              " 'escalones']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando el **arhcivo de labels**, le asigno un *valor numerico* para que la `IA` pueda interpretar las anotaciones"
      ],
      "metadata": {
        "id": "YbYsoSkhn1-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assigned_labels = { i : labels[i] for i in range(0, len(labels) ) }\n",
        "assigned_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPXmSf4Un4Kd",
        "outputId": "2a839737-a357-4f74-aa47-c57bbc29f96c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'cordon',\n",
              " 1: 'autos',\n",
              " 2: 'personas',\n",
              " 3: 'cruces',\n",
              " 4: 'pozos',\n",
              " 5: 'parar',\n",
              " 6: 'cruzar',\n",
              " 7: 'bicicleta',\n",
              " 8: 'moto',\n",
              " 9: 'escalones'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones Utiles y configuracion"
      ],
      "metadata": {
        "id": "CDDgePjQoCCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = labels"
      ],
      "metadata": {
        "id": "Z3DtEabhoCjD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = np.random.randint(0, 255, size=(len(CLASSES), 3), dtype=np.uint8)"
      ],
      "metadata": {
        "id": "Gsj3FE2ioGqt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, input_size):\n",
        "  ''' Preprocess the input image to feed to the TFLite model\n",
        "  '''\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
        "  return resized_img, original_image"
      ],
      "metadata": {
        "id": "rXD6vgJSoZpC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(interpreter, image, threshold):\n",
        "  ''' Returns a list of detection results, each a dictionary of object info.\n",
        "  '''\n",
        "\n",
        "  signature_fn = interpreter.get_signature_runner()\n",
        "\n",
        "  # Feed the input image to the model\n",
        "  output = signature_fn(images=image)\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  count = int(np.squeeze(output['output_0']))\n",
        "  scores = np.squeeze(output['output_1'])\n",
        "  classes = np.squeeze(output['output_2'])\n",
        "  boxes = np.squeeze(output['output_3'])\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results"
      ],
      "metadata": {
        "id": "Ghxh4WZ-oaLH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  ''' Run object detection on the input image and draw the detection results\n",
        "  '''\n",
        "  \n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(CLASSES[class_id], obj['score'] * 100)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8"
      ],
      "metadata": {
        "id": "m68Xs6DYocVO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_box (image, model_path, threshold):\n",
        "  base_opt = BaseOptions(model_path)\n",
        "\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  tensor_image = vision.TensorImage.create_from_file(image)\n",
        "\n",
        "  results = detector.detect(tensor_image)\n",
        "\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "    categories = obj.categories\n",
        "    for category in categories:\n",
        "      names = category.category_name\n",
        "      scores = category.score * 100\n",
        "    percentages = [float(scores)]\n",
        "    for percentage in percentages:\n",
        "      confidence = str(int(percentage)) + '%'\n",
        "      label = names + \", \" + confidence\n",
        "\n",
        "  return label"
      ],
      "metadata": {
        "id": "Ber_JMXAEhM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar Dataset"
      ],
      "metadata": {
        "id": "3N3z-QDrooH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de entrenamiento"
      ],
      "metadata": {
        "id": "uMWHqmwEoonk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = 'IBODS_LBL-1/train'"
      ],
      "metadata": {
        "id": "InmLpA7UouAg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    TRAIN_PATH,\n",
        "    TRAIN_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "V-Z4DiDIowbE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de validacion"
      ],
      "metadata": {
        "id": "we25ghDBoz4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALID_PATH = 'IBODS_LBL-1/valid'"
      ],
      "metadata": {
        "id": "dKrF-Fbdo0cn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    VALID_PATH,\n",
        "    VALID_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "EVpeegbdo2sf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargo los datos de testeo"
      ],
      "metadata": {
        "id": "Rf_R0LmKo7tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_PATH = 'IBODS_LBL-1/test'"
      ],
      "metadata": {
        "id": "wub7vz2Mo95l"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    TEST_PATH,\n",
        "    TEST_PATH,\n",
        "    labels\n",
        ")"
      ],
      "metadata": {
        "id": "rmNJlBOoo-l4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de la IA"
      ],
      "metadata": {
        "id": "kfmDFT7WpObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = object_detector.create(\n",
        "    train_data,\n",
        "    model_spec= 'efficientdet_lite1',\n",
        "    batch_size= 8,\n",
        "    train_whole_model=True,\n",
        "    epochs=100,\n",
        "    validation_data=valid_data\n",
        ")"
      ],
      "metadata": {
        "id": "4LV1ms_3pO-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testeo de la IA y su performance"
      ],
      "metadata": {
        "id": "dnZ4nw2HpRHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Hmk8-aIgpTjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvo el modelo"
      ],
      "metadata": {
        "id": "xLiSt_KKpY96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('logs')"
      ],
      "metadata": {
        "id": "oULQdRCKpd8-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(export_dir='logs')"
      ],
      "metadata": {
        "id": "vYi2BYIipiab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_tflite('logs/model.tflite', test_data)"
      ],
      "metadata": {
        "id": "sZLF_VFDploi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "1LJza3uUpoOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = QuantizationConfig.for_float16()"
      ],
      "metadata": {
        "id": "VsgwnBNSpo1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('logs/model1.tflite')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "7SHpEPMepsXy",
        "outputId": "112fb287-adcf-4a22-e786-fed81e3049a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-fac64049725a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/model1.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtflite_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m       \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignature_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0msignature_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m   \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 949\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   debug_info_path = file_io.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     raise IOError(\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         f\"{constants.SAVED_MODEL_FILENAME_PB}}}\")\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: logs/model1.tflite/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deteccion"
      ],
      "metadata": {
        "id": "ZgUNYM4Pps7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion **simple** fotos"
      ],
      "metadata": {
        "id": "3gEnhMAMpy4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_opt = BaseOptions(\n",
        "    'logs/model1.tflite'\n",
        ")"
      ],
      "metadata": {
        "id": "UO7KUyNULaD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_opt = DetectionOptions(\n",
        "    score_threshold = 0.3, \n",
        ")"
      ],
      "metadata": {
        "id": "4dobkkEYJcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = ObjectDetectorOptions(\n",
        "    base_opt,\n",
        "    detection_opt\n",
        ")"
      ],
      "metadata": {
        "id": "VByFhTjfL40y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = ObjectDetector.create_from_options(\n",
        "    options\n",
        ")"
      ],
      "metadata": {
        "id": "14KXpdC2AQX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = vision.ObjectDetector.create_from_file('logs/model1.tflite')"
      ],
      "metadata": {
        "id": "mrOyAoyYqOHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_image = vision.TensorImage.create_from_file('IBODS_LBL-1/test/60_jpg.rf.af5b4d9b99351329bad5223344640506.jpg')"
      ],
      "metadata": {
        "id": "gR4vBgxdqQOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector.detect(tensor_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nurUDYkPbtl",
        "outputId": "8f26d46e-70f5-4bd4-9430-8d3addd41f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetectionResult(detections=[Detection(bounding_box=BoundingBox(origin_x=63, origin_y=44, width=102, height=76), categories=[Category(index=1, score=0.9296875, display_name='', category_name='autos')]), Detection(bounding_box=BoundingBox(origin_x=43, origin_y=179, width=371, height=196), categories=[Category(index=4, score=0.85546875, display_name='', category_name='pozos')]), Detection(bounding_box=BoundingBox(origin_x=158, origin_y=61, width=67, height=55), categories=[Category(index=1, score=0.765625, display_name='', category_name='autos')]), Detection(bounding_box=BoundingBox(origin_x=240, origin_y=78, width=43, height=36), categories=[Category(index=1, score=0.6875, display_name='', category_name='autos')])])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = detector.detect(tensor_image)"
      ],
      "metadata": {
        "id": "neMJCmkCqSTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsdetect = results.detections"
      ],
      "metadata": {
        "id": "tXwWqlSzR0VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsdetect[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raswBIj7xPN-",
        "outputId": "d1c46041-4750-4652-e997-0ec880bf5d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Detection(bounding_box=BoundingBox(origin_x=63, origin_y=44, width=102, height=76), categories=[Category(index=1, score=0.9296875, display_name='', category_name='autos')])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unique(list1):\n",
        "\n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "  \n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    # print list\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "jdbkb-omindw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "\n",
        "image_path = 'IBODS_LBL-1/test/60_jpg.rf.af5b4d9b99351329bad5223344640506.jpg'\n",
        "model_path = 'logs/model1.tflite'\n",
        "threshold = 0.3\n",
        "\n",
        "multi_detected_objects = [] \n",
        "\n",
        "tensor_image = vision.TensorImage.create_from_file(image_path)\n",
        "image = Image.open(image_path)\n",
        "image = np.asarray(image)\n",
        "wid = image.shape[1]\n",
        "left = wid/3\n",
        "center = left * 2\n",
        "right = wid \n",
        "\n",
        "base_opt = BaseOptions(model_path)\n",
        "detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "results = detector.detect(tensor_image)\n",
        "\n",
        "resultsdetect = results.detections\n",
        "\n",
        "_TEXT_COLOR = (0, 0, 255)\n",
        "\n",
        "w_list = []\n",
        "\n",
        "for obj in resultsdetect:\n",
        "  wa = [obj.bounding_box.width]\n",
        "  w_list.append(wa)\n",
        "  start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "  end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "  detect_img = cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "  x1 = obj.bounding_box.origin_x\n",
        "  x2 = obj.bounding_box.origin_x + obj.bounding_box.width\n",
        "  middle = obj.bounding_box.width / 2\n",
        "  Center = x2 - middle\n",
        "  x = (x1, x2)\n",
        "  if Center < left:\n",
        "    position = \"izquierda\"\n",
        "  elif Center < center:\n",
        "    position = \"centro\"\n",
        "  else:\n",
        "    position = \"derecha\"\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    multi_detected_objects.append(names)\n",
        "    scores = category.score * 100\n",
        "  count_objs = {i:multi_detected_objects.count(i) for i in multi_detected_objects}\n",
        "  contador = str(count_objs)\n",
        "  final_contador = contador.strip(\"{ }\")\n",
        "  count = dict(Counter(multi_detected_objects))\n",
        "  percentages = [float(scores)]\n",
        "  for percentage in percentages:\n",
        "    confidence = str(int(percentage)) + '%'\n",
        "    label = names + \", \" + confidence + \", \" + position\n",
        "  cv2.putText(image, label, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "  cv2.putText(image, final_contador,(right - 200, right - 10) , cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
        "\n",
        "\n",
        "detect_objs = unique(multi_detected_objects)\n",
        "print(w_list)\n",
        "print(multi_detected_objects)\n",
        "print(detect_objs)\n",
        "print(count_objs)\n",
        "print(count)\n",
        "print(contador)\n",
        "img = Image.fromarray(detect_img, 'RGB')\n",
        "img.save(f'{cwd}/result/output.png')\n",
        "img.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvnsr0I3lnxQ",
        "outputId": "0ce11aad-96e8-42af-e1b0-9211e33c4beb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102], [371], [67], [43]]\n",
            "['autos', 'pozos', 'autos', 'autos']\n",
            "['autos', 'pozos']\n",
            "{'autos': 3, 'pozos': 1}\n",
            "{'autos': 3, 'pozos': 1}\n",
            "{'autos': 3, 'pozos': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def drawBoundingBox(image_path, model_path, threshold, classes):\n",
        "\n",
        "  # Agarro el directorio (carpeta) actual\n",
        "  cwd = os.getcwd()\n",
        "\n",
        "  # Le asigno los tres parametros:\n",
        "  # - La ruta de la imagen a detectar\n",
        "  # - La ruta del modelo de IA\n",
        "  # - El umbral de la IA\n",
        "\n",
        "  image_path = image_path\n",
        "  model_path = model_path\n",
        "  threshold = threshold\n",
        "\n",
        "  # Lista de todos los objetos detectados y lista de todos los width de los objetos\n",
        "\n",
        "  multi_detected_objects = []\n",
        "  list_width = []\n",
        "\n",
        "  # Leo la imagen como un tensor\n",
        "  tensor_image = vision.TensorImage.create_from_file(image_path)\n",
        "\n",
        "  # Abro y leo la imagen como un array\n",
        "  image = Image.open(image_path)\n",
        "  image = np.asarray(image)\n",
        "\n",
        "  # Divido la imagen en 3 (Izquierda, derecha y centro) utilizando el ancho de la imagen\n",
        "\n",
        "  wid = image.shape[1]\n",
        "  left = wid/3\n",
        "  center = left * 2\n",
        "  right = wid \n",
        "\n",
        "  # Asigno las opciones de configuracion del modelo de deteccion (Que modelo, el umbral, etc)\n",
        "  base_opt = BaseOptions(model_path)\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  # Creo el modelo de deteccion\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  # Agarro los resultados de la deteccion\n",
        "  results = detector.detect(tensor_image)\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  # Creo un randomizador de colores por clase\n",
        "  CLASSES = classes\n",
        "  COLORS = np.random.randint(0, 255, size=(len(CLASSES), 3), dtype=np.uint8)\n",
        "\n",
        "  # Recorro cada objetos de los resultdos de deteccion\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "\n",
        "    # Selecciono todos los ids, nombres, porcentajes de los objetos detectados\n",
        "\n",
        "    categories = obj.categories \n",
        "    for category in categories: \n",
        "      names = category.category_name\n",
        "      multi_detected_objects.append(names) \n",
        "      scores = category.score * 100 \n",
        "      class_id = category.index\n",
        "\n",
        "    # Cuento la cantidad de objetos que se repiten por clase\n",
        "\n",
        "    count_objs = {i:multi_detected_objects.count(i) for i in multi_detected_objects} \n",
        "    contador = str(count_objs)\n",
        "    final_contador = contador.strip(\"{ }\")\n",
        "\n",
        "    # Agarro los width de todos los objetos y los meto en una lista\n",
        "\n",
        "    widths = obj.bounding_box.width\n",
        "    list_width.append(widths)\n",
        "\n",
        "    # Recorro ambas listas simultaneamente, creando una tupla con los valores de la misma posicion (El 0 de uno con el 0 del otro)\n",
        "    \n",
        "    class_width_list = [(multi_detected_objects[i], list_width[i]) for i in range(0, len(list_width))] \n",
        "\n",
        "    # Creo a porcentajes en una lista\n",
        "\n",
        "    percentages = [float(scores)]\n",
        "\n",
        "    # Por cada id (identificador unico del objeto), le asigno un color\n",
        "\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "\n",
        "    # Usando las coordenadas del punto de abajo a la izquierda, creo el punto de arriba de la derecha mediante el width y el height, y creo la bounding box, uniendo ambos puntos\n",
        "\n",
        "    start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "    end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "    detect_img = cv2.rectangle(image, start_point, end_point, color, 2)\n",
        "\n",
        "    # Creo las coordenadas de los puntos en x, los de abajo\n",
        "\n",
        "    x1 = obj.bounding_box.origin_x\n",
        "    x2 = obj.bounding_box.origin_x + obj.bounding_box.width\n",
        "\n",
        "    # Calculo para saber la posicion del objeto\n",
        "    middle = obj.bounding_box.width / 2\n",
        "    Center = x2 - middle\n",
        "\n",
        "    x = (x1, x2)\n",
        "\n",
        "    # Comprobacion de la posicion del objeto\n",
        "    if Center < left:\n",
        "      position = \"izquierda\"\n",
        "    elif Center < center:\n",
        "      position = \"centro\"\n",
        "    else:\n",
        "      position = \"derecha\"\n",
        "    \n",
        "    # Creo el texto a poner y lo pongo arriba de las bounding boxes\n",
        "\n",
        "    for percentage in percentages:\n",
        "      confidence = str(int(percentage)) + '%'\n",
        "      label = names + \", \" + confidence\n",
        "      cv2.putText(image, label, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "      cv2.putText(image, position, (obj.bounding_box.origin_x,obj.bounding_box.origin_y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "      cv2.putText(image, final_contador,(right - 200, right - 10) , cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Leo devuelta la imagen, para pasarla de array a imagen y luego la devuelvo\n",
        "  detect_objs = unique(multi_detected_objects) \n",
        "  img = Image.fromarray(detect_img, 'RGB')\n",
        "  return img, detect_objs, count_objs, class_width_list"
      ],
      "metadata": {
        "id": "18qRcDLRAoR_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, objs, contador, num_width = drawBoundingBox('IBODS_LBL-1/test/60_jpg.rf.af5b4d9b99351329bad5223344640506.jpg','logs/model1.tflite', 0.3, labels)\n",
        "img.save(f'{cwd}/result/output.png')\n",
        "print(objs, contador, num_width)"
      ],
      "metadata": {
        "id": "tf6y1Rcm-xLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1440a9-64a7-494d-fdec-18b01e71a392"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['autos', 'pozos'] {'autos': 3, 'pozos': 1} [('autos', 102), ('pozos', 371), ('autos', 67), ('autos', 43)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "os.mkdir(f'{cwd}/result')"
      ],
      "metadata": {
        "id": "vMfbx6j9LzTM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion **compleja** fotos"
      ],
      "metadata": {
        "id": "hE4m-KPaqWRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "os.mkdir(f'{cwd}/result')"
      ],
      "metadata": {
        "id": "qRkGBtB0qWzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = os.getcwd()\n",
        "\n",
        "DETECTION_THRESHOLD = 0.3\n",
        "\n",
        "# Change the test file path to your test image\n",
        "INPUT_IMAGE_PATH = 'IBODS_LBL-1/test/00--91-_png_jpg.rf.d3502e507f2bb074188f809e480b2fdb.jpg'\n",
        "\n",
        "im = Image.open(INPUT_IMAGE_PATH)\n",
        "im.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "im.save(f'{cwd}/result/input.png','PNG')\n",
        "\n",
        "# Load the TFLite model\n",
        "model_path = 'logs/model1.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Run inference and draw detection result on the local copy of the original file\n",
        "detection_result_image = run_odt_and_draw_results(\n",
        "    INPUT_IMAGE_PATH,\n",
        "    interpreter,\n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "\n",
        "# Show the detection result\n",
        "img = Image.fromarray(detection_result_image)\n",
        "img.save(f'{cwd}/result/output.png')"
      ],
      "metadata": {
        "id": "hJ_pluR7qbXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deteccion en video"
      ],
      "metadata": {
        "id": "XIEa4jO8qftk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"No se puede abrir la camara\")\n",
        "    exit()\n",
        "\n",
        "while True:\n",
        "  ret,frame = cap.read() # Voy agarrando los frames\n",
        "\n",
        "  if ret == True: # Si leyo correctamente los frames, signfica que el retun (ret) es true, por lo que ejecuto el codigo en ese caso\n",
        "    cv2.cvtColor(frame, cv2.COLOR_BGRRGB) # Convierto todos los frames al espectro RGB\n",
        "    tensor_image = vision.TensorImage.create_from_array(frame) # Convierto todos los frames a tensores\n",
        "    drawBoundingBox(tensor_image, 'logs/model1.tflite', 0.3, labels)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "  if not ret:\n",
        "        print(\"No puedo recibir imagenes (finalizaste la trasmision?). Saliendo ...\")\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "JDsFyKYHqgPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codigo Viejo o Extra"
      ],
      "metadata": {
        "id": "q3zb9BL8eIg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drawBox(image_path, model_path, threshold):\n",
        "\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  base_opt = BaseOptions(model_path)\n",
        "  detection_opt = DetectionOptions(score_threshold = threshold)\n",
        "  options = ObjectDetectorOptions(base_opt, detection_opt)\n",
        "\n",
        "  detector = ObjectDetector.create_from_options(options)\n",
        "\n",
        "  results = detector.detect(image)\n",
        "\n",
        "  resultsdetect = results.detections\n",
        "\n",
        "  _TEXT_COLOR = (0, 0, 255)\n",
        "\n",
        "  for obj in resultsdetect:\n",
        "    start_point = obj.bounding_box.origin_x, obj.bounding_box.origin_y \n",
        "    end_point = obj.bounding_box.origin_x + obj.bounding_box.width, obj.bounding_box.origin_y + obj.bounding_box.height\n",
        "  detect_img = cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "   \n",
        "  return detect_img"
      ],
      "metadata": {
        "id": "Y2rqYo4WMVYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  width = [obj.bounding_box.width]\n",
        "  for wid in width:\n",
        "    print(wid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3Qlpk9DPeX4",
        "outputId": "9d98d77a-88a1-499c-8330-989e08e48817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "371\n",
            "67\n",
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    print(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zaq7eR4tBlzP",
        "outputId": "99192b2a-a197-4915-deed-c4f308a163d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autos\n",
            "pozos\n",
            "autos\n",
            "autos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in resultsdetect:\n",
        "  categories = obj.categories\n",
        "  for category in categories:\n",
        "    names = category.category_name\n",
        "    scores = category.score * 100\n",
        "  percentages = [float(scores)]\n",
        "  for percentage in percentages:\n",
        "    confidence = str(int(percentage)) + '%'\n",
        "    label = names + \", \" + confidence\n",
        "    print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXmM4gz-bbM",
        "outputId": "43d42af1-6ff9-4aed-d7f0-ec815e6e8a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autos, 92%\n",
            "pozos, 85%\n",
            "autos, 76%\n",
            "autos, 68%\n"
          ]
        }
      ]
    }
  ]
}